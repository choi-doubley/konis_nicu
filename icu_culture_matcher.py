import pandas as pd
import streamlit as st
from datetime import datetime
import io
from collections import Counter
import re

# ë‚ ì§œ ìë™ ì¸ì‹
def fix_time_format(val):
    val_str = str(val)
    
    # ì‹œê°„ ì •ë³´ê°€ ë¶™ì€ í˜•ì‹ì—ì„œ ì˜ëª»ëœ 6ìë¦¬ ìˆ«ìë§Œ ì‹œê°„ìœ¼ë¡œ ê³ ì¹˜ê¸°
    # ì˜ˆ: "2025-03-08 075844" ë˜ëŠ” "2025-03-08 07:5844" â†’ "2025-03-08 07:58:44"
    match = re.match(r'(.*\s)(\d{2}):?(\d{2})(\d{2})$', val_str)
    if match:
        return f"{match.group(1)}{match.group(2)}:{match.group(3)}:{match.group(4)}"
    
    # í˜¹ì‹œ ê·¸ëƒ¥ 6ìë¦¬ ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°ì—ë„ ëŒ€ì‘
    match2 = re.match(r'(\d{2})(\d{2})(\d{2})$', val_str)
    if match2:
        return f"{match2.group(1)}:{match2.group(2)}:{match2.group(3)}"
    
    return val_str
    
def parse_dates_safe(series):
    known_formats = [
        "%Y-%m-%d", "%Y/%m/%d", "%d-%m-%Y", "%d/%m/%Y",
        "%Y-%m-%d %H:%M", "%Y/%m/%d %H:%M", "%Y-%m-%d %H%M",
        "%Y/%m/%d %H%M", "%Y-%m-%d %H:%M:%S", "%Y/%m/%d %H:%M:%S"
    ]
    def try_parse(val):
        if pd.isna(val): return pd.NaT
        val = fix_time_format(val)  # ğŸ‘ˆ ì—¬ê¸° ì¶”ê°€
        for fmt in known_formats:
            try:
                return datetime.strptime(str(val), fmt)
            except:
                continue
        try:
            return pd.to_datetime(val, errors='coerce')
        except:
            return pd.NaT
    return series.apply(try_parse)

# ì´ˆì„± ì¶”ì¶œ í•¨ìˆ˜
def get_initials(hangul_string):
    CHOSUNG_LIST = ['ã„±', 'ã„²', 'ã„´', 'ã„·', 'ã„¸', 'ã„¹',
                    'ã…', 'ã…‚', 'ã…ƒ', 'ã……', 'ã…†', 'ã…‡',
                    'ã…ˆ', 'ã…‰', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…']
    initials = ''
    for char in str(hangul_string):
        if 'ê°€' <= char <= 'í£':
            char_code = ord(char) - ord('ê°€')
            cho = char_code // (21 * 28)
            initials += CHOSUNG_LIST[cho]
        else:
            initials += char
    return initials

# ìë™ ì»¬ëŸ¼ íƒìƒ‰
def find_column(candidates, columns):
    for candidate in candidates:
        for col in columns:
            if candidate.lower().replace(" ", "") in col.lower().replace(" ", ""):
                return col
    return None

# êµ¬ë¶„ì ìë™ ê°ì§€
def detect_delimiter(series):
    sample_values = series.dropna().astype(str).head(100)
    delimiters = ['/', '-', '|', ',', ' ']
    counts = Counter()
    for val in sample_values:
        for delim in delimiters:
            if delim in val:
                counts[delim] += 1
    return counts.most_common(1)[0][0] if counts else '/'

# Streamlit ì‹œì‘
st.set_page_config(page_title="NICU KONIS Matcher", layout="centered")
st.markdown("<h1 style='text-align:center;'>ğŸ‘¶ NICU KONIS<br>í˜ˆì•¡ë°°ì–‘ì–‘ì„±í™˜ì ì‘ì„± ë„ìš°ë¯¸</h1>", unsafe_allow_html=True)
st.markdown(
"<div style='text-align:right; font-size: 0.9em; color: gray;'>"
"ìµœì¢… ì—…ë°ì´íŠ¸: 2025-04-19<br> ë¬¸ì˜: cyypedr@gmail.com"
"</div>", unsafe_allow_html=True)


# íŒŒì¼ ì—…ë¡œë“œ
icu_file = st.file_uploader("ğŸ‘¶ ì¤‘í™˜ìì‹¤ ì…í‡´ì‹¤ íŒŒì¼", type=["xlsx"])
culture_file = st.file_uploader("ğŸ§« í˜ˆì•¡ë°°ì–‘ íŒŒì¼", type=["xlsx"])
bsi_file = st.file_uploader("ğŸš¨ BSI í™˜ìëª©ë¡ íŒŒì¼ (optional)", type=["xlsx"])
info_file = st.file_uploader("ğŸ“„ ì¶”ê°€ í™˜ìì •ë³´ íŒŒì¼ (optional)", type=["xlsx"])

if icu_file and culture_file:
    icu_df = pd.read_excel(icu_file)
    culture_df = pd.read_excel(culture_file)
    bsi_df = pd.read_excel(bsi_file) if bsi_file else pd.DataFrame()
    info_df = pd.read_excel(info_file) if info_file else pd.DataFrame()

    st.subheader("ğŸ§¸ ì¤‘í™˜ìì‹¤ íŒŒì¼ ì»¬ëŸ¼ ì„ íƒ")
    icu_id = st.selectbox("ğŸ†” í™˜ì ID ì»¬ëŸ¼", icu_df.columns, index=icu_df.columns.get_loc(find_column(["í™˜ìë²ˆí˜¸", "ë³‘ë¡ë²ˆí˜¸", "patientid", "patient_id"], icu_df.columns) or icu_df.columns[0]))
    icu_in = st.selectbox("ğŸ“… ì…ì‹¤ì¼", icu_df.columns, index=icu_df.columns.get_loc(find_column(["ì…ì‹¤"], icu_df.columns) or icu_df.columns[0]))
    icu_out = st.selectbox("ğŸ“… í‡´ì‹¤ì¼", icu_df.columns, index=icu_df.columns.get_loc(find_column(["í‡´ì‹¤"], icu_df.columns) or icu_df.columns[0]))

    st.subheader("ğŸ§« í˜ˆì•¡ë°°ì–‘ íŒŒì¼ ì»¬ëŸ¼ ì„ íƒ")
    culture_id = st.selectbox("ğŸ†” í™˜ì ID", culture_df.columns, index=culture_df.columns.get_loc(find_column(["í™˜ìë²ˆí˜¸", "ë³‘ë¡ë²ˆí˜¸", "patientid", "patient_id"], culture_df.columns) or culture_df.columns[0]))
    culture_ward = st.selectbox("ë³‘ë™(ì‹œí–‰ë¶€ì„œ)", culture_df.columns, index=culture_df.columns.get_loc(find_column(["ë³‘ë™", "ë¶€ì„œ"], culture_df.columns) or culture_df.columns[0]))
    culture_date = st.selectbox("ğŸ“… í˜ˆì•¡ë°°ì–‘ì¼", culture_df.columns, index=culture_df.columns.get_loc(find_column(["ì‹œí–‰ì¼", "ì±„ì·¨ì¼", "ê²€ì‚¬ì¼","ì ‘ìˆ˜ì¼"], culture_df.columns) or culture_df.columns[0]))
    use_result_col = st.checkbox("â” ë¶„ë¦¬ê·  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤", value=False)
    use_result_col = not use_result_col
    if use_result_col:
        culture_result = st.selectbox("ğŸ¦  í˜ˆì•¡ë°°ì–‘ ê²°ê³¼(ë¶„ë¦¬ê· ) ì»¬ëŸ¼", culture_df.columns, index=culture_df.columns.get_loc(find_column(["ë¯¸ìƒë¬¼","ê²°ê³¼"], culture_df.columns) or culture_df.columns[0]))

    if not bsi_df.empty:
        st.subheader("ğŸš¨ BSI ì—¬ë¶€ íŒŒì¼ ì»¬ëŸ¼ ì„ íƒ")
        bsi_id_col = st.selectbox("ğŸ†” í™˜ì ID", bsi_df.columns,
            index=bsi_df.columns.get_loc(find_column(["í™˜ìë²ˆí˜¸", "ë³‘ë¡ë²ˆí˜¸", "patientid", "patient_id"], bsi_df.columns) or bsi_df.columns[0])
        )

    # ë³‘í•©ì— ì‚¬ìš©í•  ì „ì²´ í›„ë³´ íŒŒì¼
    all_column_sources = {
        "ì¤‘í™˜ìì‹¤ íŒŒì¼": icu_df,
        "í˜ˆì•¡ë°°ì–‘ íŒŒì¼": culture_df
    }

    if not bsi_df.empty:
        all_column_sources["BSI íŒŒì¼"] = bsi_df
    
    if not info_df.empty:
        all_column_sources["ì¶”ê°€ì •ë³´ íŒŒì¼"] = info_df

    # í•­ìƒ "í˜ˆì•¡ë°°ì–‘ íŒŒì¼"ì„ ì²« ë²ˆì§¸ë¡œ ë³´ì´ë„ë¡ ì¬ì •ë ¬
    all_column_options = ["í˜ˆì•¡ë°°ì–‘ íŒŒì¼"] + [k for k in all_column_sources.keys() if k != "í˜ˆì•¡ë°°ì–‘ íŒŒì¼"]

    st.markdown("---")
    st.markdown("### ğŸ“… ìƒë…„ì›”ì¼ ì •ë³´")
    birth_unavailable = st.checkbox("â” ìƒë…„ì›”ì¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤", value=False)
    if not birth_unavailable:
        birth_source = st.selectbox("ğŸ“ ìƒë…„ì›”ì¼ì´ ìˆëŠ” íŒŒì¼", all_column_options, key="birth_src", index=0)
        birth_df = all_column_sources[birth_source]
        birth_id_col = st.selectbox("ğŸ†” í™˜ì ID ì»¬ëŸ¼", birth_df.columns, key="birth_id", index=birth_df.columns.get_loc(find_column(["í™˜ìë²ˆí˜¸", "ë³‘ë¡ë²ˆí˜¸", "patientid"], birth_df.columns) or birth_df.columns[0]))
        birth_col = st.selectbox("ğŸ“… ìƒë…„ì›”ì¼ ì»¬ëŸ¼", birth_df.columns, key="birth_col", index=birth_df.columns.get_loc(find_column(["ìƒë…„ì›”ì¼", "birthdate", "dob"], birth_df.columns) or birth_df.columns[0]))

    st.markdown("---")
    st.markdown("### ğŸ‘¶ ì´ë¦„ ì •ë³´")
    name_source = st.selectbox("ğŸ“ ì´ë¦„ì´ ìˆëŠ” íŒŒì¼", all_column_options, key="name_src", index=0)
    name_df = all_column_sources[name_source]
    name_id_col = st.selectbox("ğŸ”‘ í™˜ì ID ì»¬ëŸ¼", name_df.columns, key="name_id", index=name_df.columns.get_loc(find_column(["í™˜ìë²ˆí˜¸", "ë³‘ë¡ë²ˆí˜¸", "patientid"], name_df.columns) or name_df.columns[0]))
    name_col = st.selectbox("ğŸ§’ ì´ë¦„ ì»¬ëŸ¼", name_df.columns, key="name_col", index=name_df.columns.get_loc(find_column(["í™˜ìëª…","ì´ë¦„", "ì„±ëª…", "name"], name_df.columns) or name_df.columns[0]))

    st.markdown("---")
    st.markdown("### ğŸ‘¦ğŸ‘§ ì„±ë³„ ì •ë³´")
    gender_source = st.selectbox("ğŸ“ ì„±ë³„ì´ ìˆëŠ” íŒŒì¼", all_column_options, key="gender_src", index=0)
    gender_df = all_column_sources[gender_source]
    gender_id_col = st.selectbox("ğŸ†” í™˜ì ID ì»¬ëŸ¼", gender_df.columns, key="gender_id", index=gender_df.columns.get_loc(find_column(["í™˜ìë²ˆí˜¸", "ë³‘ë¡ë²ˆí˜¸", "patientid"], gender_df.columns) or gender_df.columns[0]))

    use_combined = st.checkbox("ì„±ë³„ì´ ë‹¤ë¥¸ ì •ë³´(ì˜ˆ: ë‚˜ì´)ì™€ í•˜ë‚˜ì˜ ì»¬ëŸ¼ì— í•¨ê»˜ ìˆìŒ")
    if use_combined:
        combined_col = st.selectbox("ğŸ“‘ ê²°í•©ëœ ì»¬ëŸ¼ëª…", gender_df.columns, key="combined_col", index=gender_df.columns.get_loc(find_column(["ì„±ë³„/ë‚˜ì´", "S/A", "S|A"], gender_df.columns) or gender_df.columns[0]))
        detected_delim = detect_delimiter(gender_df[combined_col])
        delimiter = st.text_input("ğŸ”¹ êµ¬ë¶„ì (ì˜ˆ: /)", value=detected_delim)
        position = st.radio("ğŸ”¹ ì„±ë³„ì€ êµ¬ë¶„ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì–´ë””ì— ìˆë‚˜ìš”?", ["ì•", "ë’¤"], horizontal=True)
    else:
        gender_col = st.selectbox("ì„±ë³„ ì»¬ëŸ¼", gender_df.columns, key="gender_col", index=gender_df.columns.get_loc(find_column(["ì„±ë³„", "gender", "sex"], gender_df.columns) or gender_df.columns[0]))

    if st.button("ğŸ” ë§¤ì¹­ ì‹¤í–‰"):
        # ë‚ ì§œ ì²˜ë¦¬       
        icu_df[icu_in] = parse_dates_safe(icu_df[icu_in])
        icu_df[icu_out] = parse_dates_safe(icu_df[icu_out])
        culture_df[culture_date] = parse_dates_safe(culture_df[culture_date])
     
        # merge_asofë¥¼ ìœ„í•œ ì‚¬ë³¸ ë° merge_id ìƒì„±
        icu_df_sorted = icu_df.copy()
        icu_df_sorted["merge_id"] = icu_df_sorted[icu_id]
        icu_df_sorted[icu_in] = pd.to_datetime(icu_df_sorted[icu_in])

        culture_df_sorted = culture_df.copy()
        culture_df_sorted["merge_id"] = culture_df_sorted[culture_id]
        culture_df_sorted[culture_date] = pd.to_datetime(culture_df_sorted[culture_date])

        icu_df_sorted = icu_df_sorted.sort_values(by=["merge_id", icu_in])
        culture_df_sorted = culture_df_sorted.sort_values(by=["merge_id", culture_date])

        # í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
        cols_to_use = [icu_in, icu_out, icu_id, "merge_id"]
        missing_cols = [col for col in cols_to_use if col not in icu_df_sorted.columns]
        if missing_cols:
            st.error(f"âŒ ICU íŒŒì¼ì—ì„œ ë‹¤ìŒ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_cols)}")
            st.stop()

        assert pd.api.types.is_datetime64_any_dtype(culture_df_sorted[culture_date]), "culture_date is not datetime"
        assert pd.api.types.is_datetime64_any_dtype(icu_df_sorted[icu_in]), "icu_in is not datetime"

        
        # merge_asof ì‹¤í–‰
        merged = pd.merge_asof(
            culture_df_sorted.sort_values(by=["merge_id", culture_date]),
            icu_df_sorted[cols_to_use].sort_values(by=["merge_id", icu_in]),
            by="merge_id",
            left_on=culture_date,
            right_on=icu_in,
            direction="backward"
        )


        # ë³‘í•© ì§í›„ í•„ìš” ì—†ëŠ” ì»¬ëŸ¼ ì œê±°
        merged.drop(columns=["merge_id", icu_id], inplace=True)

        # ìº˜ë¦°ë” ë°ì´ ë²”ìœ„ ê³„ì‚°
        merged['culture_date_day'] = merged[culture_date].dt.date
        merged['icu_in_day'] = merged[icu_in].dt.date
        merged['icu_out_day'] = merged[icu_out].dt.date
        merged['icu_day_start'] = merged['icu_in_day'] + pd.Timedelta(days=2)
        merged['icu_day_end'] = merged['icu_out_day'] + pd.Timedelta(days=1)

        # ICU ê¸°ê°„ ì•ˆì— í¬í•¨ëœ matched
        matched = merged[
            (merged['culture_date_day'] >= merged['icu_day_start']) &
            (merged['culture_date_day'] <= merged['icu_day_end'])
        ]

        # unmatchedëŠ” culture_df ì¤‘ matchedë˜ì§€ ì•Šì€ ê²ƒ
        matched_keys = matched[[culture_id, culture_date]].drop_duplicates()
        unmatched = culture_df.merge(matched_keys, on=[culture_id, culture_date], how='outer', indicator=True)
        unmatched = unmatched[unmatched['_merge'] == 'left_only'].drop(columns=['_merge'])

        # result = matched + unmatchedë¡œ culture_dfì˜ ëª¨ë“  ë°ì´í„° ìœ ì§€
        result = pd.concat([matched, unmatched], ignore_index=True, sort=False)
        result = result.drop_duplicates(subset=[culture_id, culture_date, culture_result] if use_result_col else [culture_id, culture_date])

        
        # ì´ë¦„ ì´ˆì„± ë³€í™˜ ë³‘í•©
        name_df = name_df[[name_id_col, name_col]].copy()
        name_df = name_df.drop_duplicates(subset=[name_id_col], keep="last") ## ë§ˆì§€ë§‰ ì´ë¦„ì„ ë‚¨ê¹€
        name_df['ì´ë¦„'] = name_df[name_col].apply(get_initials)
        result = result.merge(name_df[[name_id_col, 'ì´ë¦„']], left_on=culture_id, right_on=name_id_col, how='left')

        # ì„±ë³„ ë³‘í•©
        if use_combined:
            comb_df = gender_df[[gender_id_col, combined_col]].copy()
            comb_df = comb_df.drop_duplicates(subset=[gender_id_col])
            if position == "ì•":
                comb_df['ì„±ë³„'] = comb_df[combined_col].str.split(delimiter).str[0]
            else:
                comb_df['ì„±ë³„'] = comb_df[combined_col].str.split(delimiter).str[-1]
            result = result.merge(comb_df[[gender_id_col, 'ì„±ë³„']], left_on=culture_id, right_on=gender_id_col, how='left')
        else:
            gender_df = gender_df.drop_duplicates(subset=[gender_id_col])
            gender_df = gender_df[[gender_id_col, gender_col]].rename(columns={gender_col: 'ì„±ë³„'})
            result = result.merge(gender_df, left_on=culture_id, right_on=gender_id_col, how='left')

        # ìƒë…„ì›”ì¼ ë³‘í•© (ì„ íƒì )
        birth_column_success = False ## ê¸°ë³¸ê°’ ì„¤ì •
        if not birth_unavailable:
            try:
                birth_df = birth_df[[birth_id_col, birth_col]].copy()

                # ë¬¸ìì—´ ê¸¸ì´ ê¸°ì¤€ í•„í„° (ê¸¸ì´ 8 ì´ìƒì´ 50% ì´ìƒì´ì–´ì•¼ í•¨)
                str_lengths = birth_df[birth_col].astype(str).str.len()
                long_enough_ratio = (str_lengths >= 8).mean()

                if long_enough_ratio < 0.5:
                    st.warning("âŒ ì„ íƒí•œ ìƒë…„ì›”ì¼ ì»¬ëŸ¼ì˜ ê°’ ëŒ€ë¶€ë¶„ì´ ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ì»¬ëŸ¼ ì„ íƒì„ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.")
                else:
                    # ë‚ ì§œë¡œ íŒŒì‹± ì‹œë„
                    parsed_birth = parse_dates_safe(birth_df[birth_col])
                    valid_ratio = parsed_birth.notna().mean()

                    if valid_ratio < 0.5:
                        st.warning("âš ï¸ ìƒë…„ì›”ì¼ ì»¬ëŸ¼ì˜ ê°’ ì¤‘ ë‹¤ìˆ˜ê°€ ë‚ ì§œë¡œ ë³€í™˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¼ë¶€ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    else:
                        birth_df[birth_col] = parsed_birth
                        st.info("ğŸ“… ìƒë…„ì›”ì¼ ì»¬ëŸ¼ì´ ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ë˜ì–´ ìˆì–´ ìë™ìœ¼ë¡œ ë‚ ì§œë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.")
                        result = result.merge(birth_df, left_on=culture_id, right_on=birth_id_col, how='left')
                        result.rename(columns={birth_col: "ìƒë…„ì›”ì¼"}, inplace=True)
                        birth_column_success = "ìƒë…„ì›”ì¼" in result.columns

            except Exception as e:
                st.warning(f"âš ï¸ ìƒë…„ì›”ì¼ ë³‘í•©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")

        result = result.drop_duplicates(subset=[culture_id, culture_date, culture_result] if use_result_col else [culture_id, culture_date])
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        result.rename(columns={
            culture_id: "í™˜ìID",
            icu_in: "ì…ì‹¤ì¼",
            icu_out: "í‡´ì‹¤ì¼",
            culture_date: "í˜ˆì•¡ë°°ì–‘ì¼",
            culture_ward: "ì‹œí–‰ë³‘ë™"
        }, inplace=True)
        
        if use_result_col:
            result.rename(columns={culture_result: "ë¶„ë¦¬ê· "}, inplace=True)

        # ê¸°ì¡´ "ë¹„ê³ " ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ë©´ ì‚­ì œí•˜ê³  ìƒˆë¡œ ìƒì„±
        # ë¹„ê³  ì»¬ëŸ¼ ì¶”ê°€: NICU/ì‹ ìƒì•„ í¬í•¨ + ICU ì…ì‹¤ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
        if "ë¹„ê³ " in result.columns:
            result.drop(columns=["ë¹„ê³ "], inplace=True)            
        result["ë¹„ê³ "] = None
        
        result.loc[
            result["ì‹œí–‰ë³‘ë™"].str.contains("NICU|ì‹ ìƒì•„", na=False) & result["ì…ì‹¤ì¼"].isna(),
            "ë¹„ê³ "
        ] = "ì…í‡´ì‹¤ì¼ í™•ì¸"


        # ì •ë ¬ ë° ì¼ë ¨ë²ˆí˜¸
        result_sorted = result.sort_values(
            by=["ë¹„ê³ ", "ì…ì‹¤ì¼", "í˜ˆì•¡ë°°ì–‘ì¼"],
            ascending=[False, True, True],
            na_position="last"
            )        
        result_sorted.insert(0, "No", range(1, len(result_sorted) + 1))

        # BSI ì—¬ë¶€ ë³‘í•©
        if not bsi_df.empty and 'bsi_id_col' in locals():
            result_sorted["BSI"] = result_sorted["í™˜ìID"].isin(bsi_df[bsi_id_col]).map({True: "Y", False: None})
    
        # í™˜ìIDë¥¼ ë¬¸ìì—´ë¡œ ê°•ì œ ë³€í™˜
        result_sorted["í™˜ìID"] = result_sorted["í™˜ìID"].astype(str)

        # ë‚ ì§œ í¬ë§·ì„ yyyy-mm-ddë¡œ í†µì¼
        for col in ["ì…ì‹¤ì¼", "í‡´ì‹¤ì¼", "í˜ˆì•¡ë°°ì–‘ì¼", "ìƒë…„ì›”ì¼"]:
            if col in result_sorted.columns:
                result_sorted[col] = pd.to_datetime(result_sorted[col], errors="coerce").dt.strftime("%Y-%m-%d")

        
        # ì„ íƒ ì»¬ëŸ¼ ì¶œë ¥
        columns_to_show = ["No", "í™˜ìID", "ì´ë¦„", "ì„±ë³„"]
        if birth_column_success and "ìƒë…„ì›”ì¼" in result_sorted.columns:
            columns_to_show.append("ìƒë…„ì›”ì¼")
        columns_to_show += [col for col in ["ì…ì‹¤ì¼", "í‡´ì‹¤ì¼", "í˜ˆì•¡ë°°ì–‘ì¼", "ë¶„ë¦¬ê· ", "BSI","ì‹œí–‰ë³‘ë™","ë¹„ê³ "] if col in result_sorted.columns]

        # âœ… ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒí•´ì„œ ì¶œë ¥ (KeyError ë°©ì§€)
        columns_to_show = [col for col in columns_to_show if col in result_sorted.columns]

        st.success("âœ… ë§¤ì¹­ ì™„ë£Œ! ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(result_sorted[columns_to_show], use_container_width=True)

        output = io.BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            result_sorted[columns_to_show] = result_sorted[columns_to_show].astype({"í™˜ìID": str})
            result_sorted[columns_to_show].to_excel(writer, index=False)
        output.seek(0)

        st.download_button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ (.xlsx)", data=output,
                           file_name="matched_result.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
