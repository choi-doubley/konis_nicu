## py -m streamlit run icu_culture_matcher_streamlit.py


import pandas as pd
import streamlit as st
from datetime import datetime
import io
from collections import Counter
import re

# ë‚ ì§œ ìë™ ì¸ì‹
def fix_time_format(val):
    val_str = str(val)
    
    # ì‹œê°„ ì •ë³´ê°€ ë¶™ì€ í˜•ì‹ì—ì„œ ì˜ëª»ëœ 6ìë¦¬ ìˆ«ìë§Œ ì‹œê°„ìœ¼ë¡œ ê³ ì¹˜ê¸°
    # ì˜ˆ: "2025-03-08 075844" ë˜ëŠ” "2025-03-08 07:5844" â†’ "2025-03-08 07:58:44"
    match = re.match(r'(.*\s)(\d{2}):?(\d{2})(\d{2})$', val_str)
    if match:
        return f"{match.group(1)}{match.group(2)}:{match.group(3)}:{match.group(4)}"
    
    # í˜¹ì‹œ ê·¸ëƒ¥ 6ìë¦¬ ìˆ«ìë§Œ ìˆëŠ” ê²½ìš°ì—ë„ ëŒ€ì‘
    match2 = re.match(r'(\d{2})(\d{2})(\d{2})$', val_str)
    if match2:
        return f"{match2.group(1)}:{match2.group(2)}:{match2.group(3)}"
    
    return val_str
    
def parse_dates_safe(series):
    known_formats = [
        "%Y-%m-%d", "%Y/%m/%d", "%d-%m-%Y", "%d/%m/%Y",
        "%Y-%m-%d %H:%M", "%Y/%m/%d %H:%M", "%Y-%m-%d %H%M",
        "%Y/%m/%d %H%M", "%Y-%m-%d %H:%M:%S", "%Y/%m/%d %H:%M:%S"
    ]
    def try_parse(val):
        if pd.isna(val): return pd.NaT
        val = fix_time_format(val)  # ğŸ‘ˆ ì—¬ê¸° ì¶”ê°€
        for fmt in known_formats:
            try:
                return datetime.strptime(str(val), fmt)
            except:
                continue
        try:
            return pd.to_datetime(val, errors='coerce')
        except:
            return pd.NaT
    return series.apply(try_parse)

# ì´ˆì„± ì¶”ì¶œ í•¨ìˆ˜
def get_initials(hangul_string):
    CHOSUNG_LIST = ['ã„±', 'ã„²', 'ã„´', 'ã„·', 'ã„¸', 'ã„¹',
                    'ã…', 'ã…‚', 'ã…ƒ', 'ã……', 'ã…†', 'ã…‡',
                    'ã…ˆ', 'ã…‰', 'ã…Š', 'ã…‹', 'ã…Œ', 'ã…', 'ã…']
    initials = ''
    for char in str(hangul_string):
        if 'ê°€' <= char <= 'í£':
            char_code = ord(char) - ord('ê°€')
            cho = char_code // (21 * 28)
            initials += CHOSUNG_LIST[cho]
        else:
            initials += char
    return initials

# ìë™ ì»¬ëŸ¼ íƒìƒ‰
def find_column(candidates, columns):
    for candidate in candidates:
        for col in columns:
            if candidate.lower().replace(" ", "") in col.lower().replace(" ", ""):
                return col
    return None

# êµ¬ë¶„ì ìë™ ê°ì§€
def detect_delimiter(series):
    sample_values = series.dropna().astype(str).head(100)
    delimiters = ['/', '-', '|', ',', ' ']
    counts = Counter()
    for val in sample_values:
        for delim in delimiters:
            if delim in val:
                counts[delim] += 1
    return counts.most_common(1)[0][0] if counts else '/'

# Streamlit ì‹œì‘
st.set_page_config(page_title="NICU KONIS Matcher", layout="centered")
st.markdown("<h1 style='text-align:center;'>ğŸ‘¶ NICU KONIS<br>íƒ€ë‹¹ë„ ì¡°ì‚¬ ë„ìš°ë¯¸</h1>", unsafe_allow_html=True)
st.markdown(
    "<div style='text-align:right; font-size: 0.9em; color: gray;'>"
    "<a href='https://github.com/choi-doubley/konis_nicu/blob/main/KONIS_NICU_streamlit_manual.pdf?raw=T' target='_blank'>ë§¤ë‰´ì–¼ ë‹¤ìš´ë¡œë“œ</a><br>"
    "ìµœì¢… ì—…ë°ì´íŠ¸: 2025-05-08<br>" 
    "ë¬¸ì˜: cyypedr@gmail.com"
    "</div>",
    unsafe_allow_html=True
)
#    "<a href='https://github.com/choi-doubley/konis_nicu/blob/main/KONIS_NICU_streamlit_manual.pdf?raw=T' target='_blank'>ë§¤ë‰´ì–¼ ë‹¤ìš´ë¡œë“œ</a><br>"

# íŒŒì¼ ì—…ë¡œë“œ
culture_file = st.file_uploader("ğŸ§« í˜ˆì•¡ë°°ì–‘ íŒŒì¼", type=["xlsx"])
icu_file = st.file_uploader("ğŸ‘¶ ì¤‘í™˜ìì‹¤ ì…í‡´ì‹¤ íŒŒì¼", type=["xlsx"])
bsi_file = st.file_uploader("ğŸš¨ KONIS WRAP ë“±ë¡í™˜ì íŒŒì¼ (optional)", type=["xlsx"])
info_file = st.file_uploader("ğŸ“„ ì¶”ê°€ í™˜ìì •ë³´ íŒŒì¼ (optional)", type=["xlsx"])

if icu_file and culture_file:
    icu_df = pd.read_excel(icu_file, dtype=str)
    culture_df = pd.read_excel(culture_file, dtype=str)
    bsi_df = pd.read_excel(bsi_file, dtype=str) if bsi_file else pd.DataFrame()
    info_df = pd.read_excel(info_file, dtype=str) if info_file else pd.DataFrame()

    st.subheader("ğŸ§« í˜ˆì•¡ë°°ì–‘ íŒŒì¼ ì»¬ëŸ¼ ì„ íƒ")
    culture_id = st.selectbox("ğŸ†” í™˜ì ID", culture_df.columns, index=culture_df.columns.get_loc(find_column(["í™˜ìë²ˆí˜¸", "ë³‘ë¡ë²ˆí˜¸", "patientid", "patient_id"], culture_df.columns) or culture_df.columns[0]))
    use_ward_col = st.checkbox("â” ì‹œí–‰ë³‘ë™ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤", value=False)
    use_ward_col = not use_ward_col
    if use_ward_col:
        culture_ward = st.selectbox("ğŸš¼ ë³‘ë™(ì‹œí–‰ë¶€ì„œ)", culture_df.columns, index=culture_df.columns.get_loc(find_column(["ë³‘ë™", "ë¶€ì„œ"], culture_df.columns) or culture_df.columns[0]))
    culture_date = st.selectbox("ğŸ“… í˜ˆì•¡ë°°ì–‘ ì˜ë¢°ì¼", culture_df.columns, index=culture_df.columns.get_loc(find_column(["ì‹œí–‰ì¼", "ì±„ì·¨ì¼", "ê²€ì‚¬ì¼","ì ‘ìˆ˜ì¼"], culture_df.columns) or culture_df.columns[0]))
    use_result_col = st.checkbox("â” ë¶„ë¦¬ê·  ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤", value=False)
    use_result_col = not use_result_col
    if use_result_col:
        culture_result = st.selectbox("ğŸ¦  í˜ˆì•¡ë°°ì–‘ ê²°ê³¼(ë¶„ë¦¬ê· ) ì»¬ëŸ¼", culture_df.columns, index=culture_df.columns.get_loc(find_column(["ë¯¸ìƒë¬¼","ê²°ê³¼"], culture_df.columns) or culture_df.columns[0]))

    if not bsi_df.empty:
        st.subheader("ğŸš¨ KONIS WRAP ë“±ë¡í™˜ì ì»¬ëŸ¼ ì„ íƒ")
        bsi_id_col = st.selectbox("ğŸ†” í™˜ì ID", bsi_df.columns,
            index=bsi_df.columns.get_loc(find_column(["í™˜ìë²ˆí˜¸", "ë³‘ë¡ë²ˆí˜¸", "patientid", "patient_id"], bsi_df.columns) or bsi_df.columns[0])
        )
        
    st.subheader("ğŸ§¸ ì¤‘í™˜ìì‹¤ íŒŒì¼ ì»¬ëŸ¼ ì„ íƒ")
    icu_id = st.selectbox("ğŸ†” í™˜ì ID ì»¬ëŸ¼", icu_df.columns, index=icu_df.columns.get_loc(find_column(["í™˜ìë²ˆí˜¸", "ë³‘ë¡ë²ˆí˜¸", "patientid", "patient_id"], icu_df.columns) or icu_df.columns[0]))
    icu_in = st.selectbox("ğŸ“… ì…ì‹¤ì¼", icu_df.columns, index=icu_df.columns.get_loc(find_column(["ì…ì‹¤"], icu_df.columns) or icu_df.columns[0]))
    icu_out = st.selectbox("ğŸ“… í‡´ì‹¤ì¼", icu_df.columns, index=icu_df.columns.get_loc(find_column(["í‡´ì‹¤"], icu_df.columns) or icu_df.columns[0]))



    # ë³‘í•©ì— ì‚¬ìš©í•  ì „ì²´ í›„ë³´ íŒŒì¼
    all_column_sources = {
        "ì¤‘í™˜ìì‹¤ íŒŒì¼": icu_df,
        "í˜ˆì•¡ë°°ì–‘ íŒŒì¼": culture_df
    }

    if not bsi_df.empty:
        all_column_sources["BSI íŒŒì¼"] = bsi_df
    
    if not info_df.empty:
        all_column_sources["ì¶”ê°€ì •ë³´ íŒŒì¼"] = info_df

    # í•­ìƒ "í˜ˆì•¡ë°°ì–‘ íŒŒì¼"ì„ ì²« ë²ˆì§¸ë¡œ ë³´ì´ë„ë¡ ì¬ì •ë ¬
    all_column_options = ["í˜ˆì•¡ë°°ì–‘ íŒŒì¼"] + [k for k in all_column_sources.keys() if k != "í˜ˆì•¡ë°°ì–‘ íŒŒì¼"]

    st.markdown("---")
    st.markdown("### ğŸ“… ìƒë…„ì›”ì¼ ì •ë³´")
    birth_unavailable = st.checkbox("â” ìƒë…„ì›”ì¼ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤", value=False)
    if not birth_unavailable:
        birth_source = st.selectbox("ğŸ“ ìƒë…„ì›”ì¼ì´ ìˆëŠ” íŒŒì¼", all_column_options, key="birth_src", index=0)
        birth_df = all_column_sources[birth_source]
        birth_id_col = st.selectbox("ğŸ†” í™˜ì ID ì»¬ëŸ¼", birth_df.columns, key="birth_id", index=birth_df.columns.get_loc(find_column(["í™˜ìë²ˆí˜¸", "ë³‘ë¡ë²ˆí˜¸", "patientid"], birth_df.columns) or birth_df.columns[0]))
        birth_col = st.selectbox("ğŸ“… ìƒë…„ì›”ì¼ ì»¬ëŸ¼", birth_df.columns, key="birth_col", index=birth_df.columns.get_loc(find_column(["ìƒë…„ì›”ì¼", "birthdate", "dob"], birth_df.columns) or birth_df.columns[0]))

    #st.markdown("---")
    #st.markdown("### ğŸ‘¶ ì´ë¦„ ì •ë³´")
    #name_source = st.selectbox("ğŸ“ ì´ë¦„ì´ ìˆëŠ” íŒŒì¼", all_column_options, key="name_src", index=0)
    #name_df = all_column_sources[name_source]
    #name_id_col = st.selectbox("ğŸ”‘ í™˜ì ID ì»¬ëŸ¼", name_df.columns, key="name_id", index=name_df.columns.get_loc(find_column(["í™˜ìë²ˆí˜¸", "ë³‘ë¡ë²ˆí˜¸", "patientid"], name_df.columns) or name_df.columns[0]))
    #name_col = st.selectbox("ğŸ§’ ì´ë¦„ ì»¬ëŸ¼", name_df.columns, key="name_col", index=name_df.columns.get_loc(find_column(["í™˜ìëª…","ì´ë¦„", "ì„±ëª…", "name"], name_df.columns) or name_df.columns[0]))

    st.markdown("---")
    st.markdown("### ğŸ‘¦ğŸ‘§ ì„±ë³„ ì •ë³´")
    gender_source = st.selectbox("ğŸ“ ì„±ë³„ì´ ìˆëŠ” íŒŒì¼", all_column_options, key="gender_src", index=0)
    gender_df = all_column_sources[gender_source]
    gender_id_col = st.selectbox("ğŸ†” í™˜ì ID ì»¬ëŸ¼", gender_df.columns, key="gender_id", index=gender_df.columns.get_loc(find_column(["í™˜ìë²ˆí˜¸", "ë³‘ë¡ë²ˆí˜¸", "patientid"], gender_df.columns) or gender_df.columns[0]))

    use_combined = st.checkbox("ì„±ë³„ì´ ë‹¤ë¥¸ ì •ë³´(ì˜ˆ: ë‚˜ì´)ì™€ í•˜ë‚˜ì˜ ì»¬ëŸ¼ì— í•¨ê»˜ ìˆìŒ")
    if use_combined:
        combined_col = st.selectbox("ğŸ“‘ ê²°í•©ëœ ì»¬ëŸ¼ëª…", gender_df.columns, key="combined_col", index=gender_df.columns.get_loc(find_column(["ì„±ë³„/ë‚˜ì´", "S/A", "S|A"], gender_df.columns) or gender_df.columns[0]))
        detected_delim = detect_delimiter(gender_df[combined_col])
        delimiter = st.text_input("ğŸ”¹ êµ¬ë¶„ì (ì˜ˆ: /)", value=detected_delim)
        position = st.radio("ğŸ”¹ ì„±ë³„ì€ êµ¬ë¶„ìë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì–´ë””ì— ìˆë‚˜ìš”?", ["ì•", "ë’¤"], horizontal=True)
    else:
        gender_col = st.selectbox("ì„±ë³„ ì»¬ëŸ¼", gender_df.columns, key="gender_col", index=gender_df.columns.get_loc(find_column(["ì„±ë³„", "gender", "sex"], gender_df.columns) or gender_df.columns[0]))

    if st.button("ğŸ” ë§¤ì¹­ ì‹¤í–‰"):
        # ë‚ ì§œ ì²˜ë¦¬
        icu_df[icu_in] = parse_dates_safe(icu_df[icu_in])
        icu_df[icu_out] = parse_dates_safe(icu_df[icu_out])
        culture_df[culture_date] = parse_dates_safe(culture_df[culture_date])

        # ICU ë°ì´í„° ë³‘í•©
        merged = culture_df.merge(
            icu_df[[icu_id, icu_in, icu_out]],
            left_on=culture_id, right_on=icu_id, how='left'
        )

        # ìº˜ë¦°ë” ë°ì´ ë²”ìœ„ ê³„ì‚°
        merged['culture_date_day'] = merged[culture_date].dt.date
        merged['icu_in_day'] = merged[icu_in].dt.date
        merged['icu_out_day'] = merged[icu_out].dt.date
        merged['icu_day_start'] = merged['icu_in_day'] + pd.Timedelta(days=2)
        merged['icu_day_end'] = merged['icu_out_day'] + pd.Timedelta(days=1)

        merged = merged.drop_duplicates(subset=[culture_id, culture_date, culture_result] if use_result_col else [culture_id, culture_date])
        merged['surv_window'] = None


        # 1. ì…ì‹¤ì¼ ì—†ëŠ” ê²½ìš° â†’ ì…í‡´ì‹¤ì¼ í™•ì¸
        merged.loc[merged['icu_in_day'].isna(), 'surv_window'] = "ì‹œí–‰ë¶€ì„œ í™•ì¸"


        # 2. ê°ì‹œê¸°ê°„ í¬í•¨ (icu_day_start â‰¤ culture_date_day â‰¤ icu_day_end or icu_day_end isna)
        condition_matched = (
            (merged['icu_day_start'].notna()) &
            (merged['culture_date_day'] >= merged['icu_day_start']) &
            (
                (merged['culture_date_day'] <= merged['icu_day_end']) |
                (merged['icu_day_end'].isna())
            )
        )
        merged.loc[condition_matched, 'surv_window'] = None  # matched â†’ ë¹„ê³  ì—†ìŒ

        # 3. ê°ì‹œê¸°ê°„ ì´ì „ (culture_date_day < icu_day_start) â†’ ê°ì‹œê¸°ê°„ ì´ì „
        condition_before = (
            merged['icu_in_day'].notna() &
            (merged['culture_date_day'] >= merged['icu_in_day']) &
            (merged['culture_date_day'] < merged['icu_day_start'])
        )
        merged.loc[condition_before, 'surv_window'] = "ê°ì‹œê¸°ê°„ ì´ì „"

        # 4. ê°ì‹œê¸°ê°„ ì´í›„ (culture_date_day > icu_day_end) â†’ ê°ì‹œê¸°ê°„ ì´í›„
        condition_after = (
            merged['icu_day_end'].notna() &
            (merged['culture_date_day'] > merged['icu_day_end'])
        )
        merged.loc[condition_after, 'surv_window'] = "ê°ì‹œê¸°ê°„ ì´í›„"

        # matched: ë¹„ê³ ê°€ Noneì¸ ê²ƒ
        matched = merged[merged['surv_window'].isna()]

        # unmatched: ë‚˜ë¨¸ì§€ ë¹„ê³ ê°€ ìˆëŠ” í–‰
        unmatched = merged[merged['surv_window'].notna()]

        # result = matched + unmatchedë¡œ culture_dfì˜ ëª¨ë“  ë°ì´í„° ìœ ì§€
        result = pd.concat([matched, unmatched], ignore_index=True, sort=False)


        # ì´ë¦„, ì„±ë³„ ë³‘í•© ì „ì— ì¤‘ë³µê°€ëŠ¥ì„± ìˆëŠ” ì—´ ì œê±°
        gender_col_name = gender_col if not use_combined else combined_col
        #for col in [name_col, "ì´ë¦„", gender_col_name, "ì„±ë³„"]:
        #    if col in result.columns:
        #        result.drop(columns=[col], inplace=True)
        
        # ì´ë¦„ ì´ˆì„± ë³€í™˜ ë³‘í•©
        #name_df = name_df[[name_id_col, name_col]].copy()
        #name_df = name_df.drop_duplicates(subset=[name_id_col], keep="last") ## ë§ˆì§€ë§‰ ì´ë¦„ì„ ë‚¨ê¹€
        #name_df['name_initial'] = name_df[name_col].apply(get_initials)
        #result = result.merge(name_df[[name_id_col, 'name_initial']], left_on=culture_id, right_on=name_id_col, how='left')

        # ì„±ë³„ ë³‘í•©     
        if use_combined:
            comb_df = gender_df[[gender_id_col, combined_col]].copy()
            comb_df = comb_df.drop_duplicates(subset=[gender_id_col])
            if position == "ì•":
                comb_df['gender'] = comb_df[combined_col].str.split(delimiter).str[0]
            else:
                comb_df['gender'] = comb_df[combined_col].str.split(delimiter).str[-1]
            result = result.merge(comb_df[[gender_id_col, 'gender']], left_on=culture_id, right_on=gender_id_col, how='left')
        else:
            gender_df = gender_df.drop_duplicates(subset=[gender_id_col])
            gender_df = gender_df[[gender_id_col, gender_col]].rename(columns={gender_col: 'gender'})
            result = result.merge(gender_df, left_on=culture_id, right_on=gender_id_col, how='left')

        # ìƒë…„ì›”ì¼ ë³‘í•© (ì„ íƒì )
        birth_column_success = False ## ê¸°ë³¸ê°’ ì„¤ì •
        if not birth_unavailable:
            for col in [birth_col, "ìƒë…„ì›”ì¼"]:
                if col in result.columns:
                    result.drop(columns=[col], inplace=True)               
            try:
                birth_df = birth_df[[birth_id_col, birth_col]].copy()
                birth_df = birth_df.drop_duplicates(subset=[birth_id_col])

                # ë¬¸ìì—´ ê¸¸ì´ ê¸°ì¤€ í•„í„° (ê¸¸ì´ 8 ì´ìƒì´ 50% ì´ìƒì´ì–´ì•¼ í•¨)
                str_lengths = birth_df[birth_col].astype(str).str.len()
                long_enough_ratio = (str_lengths >= 8).mean()

                if long_enough_ratio < 0.5:
                    st.warning("âŒ ì„ íƒí•œ ìƒë…„ì›”ì¼ ì»¬ëŸ¼ì˜ ê°’ ëŒ€ë¶€ë¶„ì´ ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. ì»¬ëŸ¼ ì„ íƒì„ ë‹¤ì‹œ í™•ì¸í•´ ì£¼ì„¸ìš”.")
                else:
                    # ë‚ ì§œë¡œ íŒŒì‹± ì‹œë„
                    parsed_birth = parse_dates_safe(birth_df[birth_col])
                    valid_ratio = parsed_birth.notna().mean()

                    if valid_ratio < 0.5:
                        st.warning("âš ï¸ ìƒë…„ì›”ì¼ ì»¬ëŸ¼ì˜ ê°’ ì¤‘ ë‹¤ìˆ˜ê°€ ë‚ ì§œë¡œ ë³€í™˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¼ë¶€ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                    else:
                        birth_df[birth_col] = parsed_birth
                        result = result.merge(birth_df, left_on=culture_id, right_on=birth_id_col, how='left')
                        result.rename(columns={birth_col: "dob"}, inplace=True)
                        birth_column_success = birth_col in result.columns ## boolean

            except Exception as e:
                st.warning(f"âš ï¸ ìƒë…„ì›”ì¼ ë³‘í•©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")


        # ë‚ ì§œ í¬ë§·ì„ yyyy-mm-ddë¡œ í†µì¼
        date_cols = [icu_in, icu_out, culture_date]
        if not birth_unavailable:
            date_cols.append("dob")

        for col in date_cols:
            if col in result:
                result[col] = pd.to_datetime(result[col], errors="coerce").dt.strftime("%Y-%m-%d")

        result = result.drop_duplicates(subset=[culture_id, culture_date, culture_result] if use_result_col else [culture_id, culture_date])        



        # ê¸°ì¡´ "ë¹„ê³ " ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ë©´ ì‚­ì œ
        # ë¹„ê³  ì»¬ëŸ¼ ì¶”ê°€: NICU/ì‹ ìƒì•„ í¬í•¨ + ICU ì…ì‹¤ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°
        if "ë¹„ê³ " in result.columns:
            result.drop(columns=["ë¹„ê³ "], inplace=True)            

        if use_ward_col and 'culture_ward' in locals() and culture_ward:
            result.loc[
                result[culture_ward].str.contains("NICU|NR|ì‹ ìƒì•„", na=False) & result[icu_in].isna(),
                "surv_window"
            ] = "ì…í‡´ì‹¤ì¼ í™•ì¸"


        # ì •ë ¬ ë° ì¼ë ¨ë²ˆí˜¸
        surv_window_sort = {
            None: 0,
            "ì…í‡´ì‹¤ì¼ í™•ì¸": 1,
            "ê°ì‹œê¸°ê°„ ì´ì „": 2,
            "ê°ì‹œê¸°ê°„ ì´í›„": 3
        }
        result["order_sort"] = result["surv_window"].map(surv_window_sort)

        # ì •ë ¬ ë° ì¼ë ¨ë²ˆí˜¸
        result_sorted = result.sort_values(
            by=["order_sort", culture_date, icu_in],
            ascending=[True, True, True],
            na_position="last"
        ).drop(columns=["order_sort"])
        result_sorted.insert(0, "No", range(1, len(result_sorted) + 1))

        # KONIS ë“±ë¡ì—¬ë¶€ ë³‘í•©
        if not bsi_df.empty and 'bsi_id_col' in locals():
            result_sorted["KONIS"] = result_sorted[culture_id].isin(bsi_df[bsi_id_col]).map({True: "Y", False: "N"})
            #result_sorted.rename(columns={"KONIS": "ë“±ë¡ì—¬ë¶€"}, inplace=True)
    
        # í™˜ìIDë¥¼ ë¬¸ìì—´ë¡œ ê°•ì œ ë³€í™˜
        result_sorted[culture_id] = result_sorted[culture_id].astype(str)
        
        # ê²°ì¸¡ ì»¬ëŸ¼ ì²˜ë¦¬
        if use_result_col and 'culture_result' in locals() and culture_result:
            result_sorted["culture_result2"]=result_sorted[culture_result]
        else: 
            result_sorted["culture_result2"]=None

        if use_ward_col and 'culture_ward' in locals() and culture_ward:
            result_sorted["culture_ward2"]=result_sorted[culture_ward]
        else: 
            result_sorted["culture_ward2"]=None           
       
        column_rename_map = {
            "No": "ë²ˆí˜¸",
            culture_id: "ë“±ë¡ë²ˆí˜¸_ID",
            #"name_initial": "ì´ë¦„_ì´ˆì„±",
            "gender": "ì„±ë³„",
            "dob": "ìƒë…„ì›”ì¼",
            icu_in: "ì…ì‹¤ì¼",
            icu_out: "í‡´ì‹¤ì¼",
            culture_date: "í˜ˆì•¡ë°°ì–‘ ì˜ë¢°ì¼",
            "culture_result2": "í˜ˆì•¡ë°°ì–‘ ë¶„ë¦¬ê· ",
            "KONIS": "KONIS WRAP ë“±ë¡ì—¬ë¶€",
            "culture_ward2": "í˜ˆì•¡ë°°ì–‘ ì‹œí–‰ë³‘ë™",
            "surv_window": "ë¹„ê³ "
        }

        for col in column_rename_map.keys():
            if col not in result_sorted.columns:
                result_sorted[col] = ""

        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
        export_df = result_sorted[list(column_rename_map.keys())].rename(columns=column_rename_map) # ê¸°ë³¸(ì™¸ë¶€ íƒ€ë‹¹ë„ ì¡°ì‚¬ìš©)
        export_df2 = export_df.copy()
        insert_loc = export_df2.columns.get_loc("í˜ˆì•¡ë°°ì–‘ ë¶„ë¦¬ê· ") + 1
        export_df2.insert(insert_loc, "BSI ë¶„ë¥˜", "") # ë‚´ë¶€ íƒ€ë‹¹ë„ ì¡°ì‚¬ìš©
        
        st.session_state["export_df1"] = export_df  
        st.session_state["export_df2"] = export_df2  
        st.session_state["matching_done"] = True

    if st.session_state.get("matching_done", False):
        st.success("âœ… ë§¤ì¹­ ì™„ë£Œ! ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(st.session_state["export_df1"], use_container_width=True, hide_index=True)
        #st.dataframe(export_df, use_container_width=True)

        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ 1
        output1 = io.BytesIO()
        with pd.ExcelWriter(output1, engine="openpyxl") as writer:
            st.session_state["export_df1"].astype({"ë“±ë¡ë²ˆí˜¸_ID": str}).to_excel(writer, index=False)
        output1.seek(0)
        st.download_button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ - ì™¸ë¶€ íƒ€ë‹¹ë„ ì¡°ì‚¬ìš© (.xlsx)", data=output1,
                           file_name="matched_result_external.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")


        output2 = io.BytesIO()
        with pd.ExcelWriter(output2, engine="openpyxl") as writer:
            st.session_state["export_df2"].astype({"ë“±ë¡ë²ˆí˜¸_ID": str}).to_excel(writer, index=False)
        output2.seek(0)
        st.download_button("ğŸ“¥ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ - ë‚´ë¶€ íƒ€ë‹¹ë„ ì¡°ì‚¬ìš© (.xlsx)", data=output2,
                           file_name="matched_result_internal.xlsx",
                           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
